{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSVEP: Offline processing using Machine Leaning Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import neceessary toolboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import require library for preprocess\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne.channels import make_standard_montage\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.datasets import eegbci\n",
    "import scipy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "# import require library for classification\n",
    "from sklearn.svm import SVC # SVM library\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # LDA library\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN library\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix # Result representation\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read biosemi file (bdf)\n",
    "raw1 = mne.io.read_raw_bdf(\"C:\\\\Users\\\\pipo_\\\\OneDrive\\\\Desktop\\\\neuromedia\\\\group1_block1.bdf\", preload=True, verbose=False) \n",
    "\n",
    "raw2 = mne.io.read_raw_bdf(\"C:\\\\Users\\\\pipo_\\\\OneDrive\\\\Desktop\\\\neuromedia\\\\group1_block2.bdf\", preload=True, verbose=False) \n",
    "\n",
    "raw3 = mne.io.read_raw_bdf(\"C:\\\\Users\\\\pipo_\\\\OneDrive\\\\Desktop\\\\neuromedia\\\\group1_block3.bdf\", preload=True, verbose=False) \n",
    "\n",
    "raw4 = mne.io.read_raw_bdf(\"C:\\\\Users\\\\pipo_\\\\OneDrive\\\\Desktop\\\\neuromedia\\\\group1_block4.bdf\", preload=True, verbose=False) \n",
    "raw = mne.concatenate_raws([raw1, raw2, raw3, raw4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data preprocessing -- set channel locations/ downsampling/ frequency filtering (bandpass)/ epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import filtfilt\n",
    "from scipy import signal\n",
    "\n",
    "# Set channel location\n",
    "montage = make_standard_montage(\"biosemi64\")\n",
    "raw.set_montage(montage, on_missing='ignore')\n",
    "\n",
    "# Downsample data (from 1024 to 512Hz) to save storage space \n",
    "raw = raw.resample(512, verbose = False)\n",
    "\n",
    "# Get events and timestamps\n",
    "events = mne.find_events(raw, shortest_event = 0, verbose = False) \n",
    "\n",
    "# Create event dictionary \n",
    "event_dict =  {'12Hz': 8,\n",
    "'24Hz': 4,\n",
    "'6Hz': 10,\n",
    "'30Hz': 2\n",
    "}\n",
    "\n",
    "# Use events and event dictionary to cut data into Epochs\n",
    "ssvep_chans = ['O1','Oz','PO3','POz','O2']  # Reject O2 becuase noisy channel\n",
    "\n",
    "Epochs = mne.Epochs(raw, events, \n",
    "    tmin= -0.5,  \n",
    "    tmax= 4.0,    \n",
    "    event_id=event_dict,\n",
    "    picks = ssvep_chans,\n",
    "    preload = True,\n",
    "    event_repeated='drop',\n",
    "    baseline= (-0.5,0),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "Epochs = Epochs.copy().crop(tmin = 0.0, tmax = 4.0)\n",
    "\n",
    "train_label = Epochs['12Hz','6Hz', '24Hz', '30Hz'].events[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Scipy Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pipo_\\AppData\\Local\\Temp\\ipykernel_9296\\1196626325.py:15: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  Epochs_data = butter_bandpass_filter(Epochs.get_data(), lowcut = 2, highcut= 40, axis = 2)\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(lowcut,highcut,fs,order):\n",
    "    nyq = 0.5*fs\n",
    "    low = lowcut/nyq\n",
    "    high = highcut/nyq\n",
    "    b,a = signal.butter(order,[low,high],'bandpass')\n",
    "    return b,a\n",
    "\n",
    "def butter_bandpass_filter(data,lowcut = 6, highcut = 30, order = 4, axis = 1):\n",
    "    b,a = butter_bandpass(lowcut,highcut,512,order)\n",
    "    y = signal.filtfilt(b,a,data,axis=axis)\n",
    "    return y\n",
    "\n",
    "Epochs_data = butter_bandpass_filter(Epochs.get_data(), lowcut = 2, highcut= 40, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 5, 2048)\n",
      "(192, 10240)\n"
     ]
    }
   ],
   "source": [
    "# Compute FFT for each epoch and return the power spectral density\n",
    "def compute_fft(epoch_data, sampling_rate):\n",
    "\n",
    "    num_epochs, num_channels, num_timepoints = epoch_data.shape\n",
    "\n",
    "    freqs = np.fft.fftfreq(num_timepoints-1, 1 / sampling_rate)\n",
    "    \n",
    "    fft_data = np.zeros((num_epochs, num_channels, len(freqs)))\n",
    "\n",
    "    # Compute FFT for each channel and each epoch\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        for ch_idx in range(num_channels):     \n",
    "            fft_result = scipy.fft.fft(epoch_data[epoch_idx, ch_idx, 0:2048])\n",
    "\n",
    "            power_spectrum = np.abs(fft_result) ** 2  # Power = |FFT|^2\n",
    "            fft_data[epoch_idx, ch_idx, :] = power_spectrum\n",
    "\n",
    "    return fft_data, freqs\n",
    "\n",
    "# Example usage\n",
    "fft_out, freqs_out = compute_fft(Epochs_data, 512)\n",
    "print(np.shape(fft_out))\n",
    "\n",
    "fft_train = np.stack([arr.flatten() for arr in fft_out])\n",
    "print(fft_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(fft_train, train_label, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetConfusionMatrix(models, X_train, X_test, y_train, y_test, target_names):\n",
    "    y_pred = models.predict(X_train)\n",
    "    print(\"Classification TRAIN DATA \\n=======================\")\n",
    "    print(classification_report(y_true= y_train, y_pred=y_pred, target_names= target_names))\n",
    "    print(\"Confusion matrix \\n=======================\")\n",
    "    print(confusion_matrix(y_true= y_train, y_pred=y_pred))\n",
    "\n",
    "    y_pred = models.predict(X_test)\n",
    "    print(\"Classification TEST DATA \\n=======================\")\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred, target_names= target_names))\n",
    "    print(\"Confusion matrix \\n=======================\")\n",
    "    print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'solver': 'svd'}\n",
      "Best cross-validation score: 0.567\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        12Hz       0.66      0.66      0.66        35\n",
      "         6Hz       0.77      0.79      0.78        29\n",
      "        24Hz       0.83      0.71      0.77        35\n",
      "        30Hz       0.72      0.80      0.76        35\n",
      "\n",
      "    accuracy                           0.74       134\n",
      "   macro avg       0.74      0.74      0.74       134\n",
      "weighted avg       0.74      0.74      0.74       134\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[23  3  4  5]\n",
      " [ 4 23  0  2]\n",
      " [ 4  2 25  4]\n",
      " [ 4  2  1 28]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        12Hz       0.71      0.77      0.74        13\n",
      "         6Hz       0.74      0.74      0.74        19\n",
      "        24Hz       0.78      0.54      0.64        13\n",
      "        30Hz       0.69      0.85      0.76        13\n",
      "\n",
      "    accuracy                           0.72        58\n",
      "   macro avg       0.73      0.72      0.72        58\n",
      "weighted avg       0.73      0.72      0.72        58\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[10  1  0  2]\n",
      " [ 1 14  1  3]\n",
      " [ 2  4  7  0]\n",
      " [ 1  0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['svd']\n",
    "}\n",
    "\n",
    "cv_splitter = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "tuned_clf_lda = GridSearchCV(estimator=lda, param_grid=param_grid,\n",
    "                    scoring='accuracy', refit='accuracy', cv=cv_splitter)\n",
    "\n",
    "tuned_clf_lda.fit(x_train, y_train)\n",
    "print(f\"Best parameters: {tuned_clf_lda.best_params_}\")\n",
    "print(f\"Best cross-validation score: {tuned_clf_lda.best_score_:.3f}\")\n",
    "label_names = ['12Hz', '6Hz', '24Hz', '30Hz']\n",
    "\n",
    "with open(\"trained_model/LDA_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tuned_clf_lda, file)\n",
    "\n",
    "GetConfusionMatrix(tuned_clf_lda, x_train, x_test, y_train, y_test, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.672\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        12Hz       1.00      1.00      1.00        35\n",
      "         6Hz       1.00      1.00      1.00        29\n",
      "        24Hz       1.00      1.00      1.00        35\n",
      "        30Hz       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[35  0  0  0]\n",
      " [ 0 29  0  0]\n",
      " [ 0  0 35  0]\n",
      " [ 0  0  0 35]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        12Hz       0.77      0.77      0.77        13\n",
      "         6Hz       0.88      0.74      0.80        19\n",
      "        24Hz       0.42      0.62      0.50        13\n",
      "        30Hz       0.80      0.62      0.70        13\n",
      "\n",
      "    accuracy                           0.69        58\n",
      "   macro avg       0.72      0.68      0.69        58\n",
      "weighted avg       0.73      0.69      0.70        58\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[10  0  3  0]\n",
      " [ 1 14  4  0]\n",
      " [ 2  1  8  2]\n",
      " [ 0  1  4  8]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C':  [10, 100],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "svm_model =  SVC(random_state=SEED, probability= False)\n",
    "cv_splitter = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "tuned_clf_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid,\n",
    "                    scoring='accuracy', refit='accuracy', cv=cv_splitter)\n",
    "\n",
    "tuned_clf_svm.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {tuned_clf_svm.best_params_}\")\n",
    "print(f\"Best cross-validation score: {tuned_clf_svm.best_score_:.3f}\")\n",
    "label_names = ['12Hz', '6Hz', '24Hz', '30Hz']\n",
    "\n",
    "with open(\"trained_model/SVM_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tuned_clf_svm, file)\n",
    "\n",
    "GetConfusionMatrix(tuned_clf_svm, x_train, x_test, y_train, y_test, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Best cross-validation score: 0.635\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        12Hz       0.74      0.74      0.74        35\n",
      "         6Hz       1.00      0.31      0.47        29\n",
      "        24Hz       0.71      0.71      0.71        35\n",
      "        30Hz       0.62      0.97      0.76        35\n",
      "\n",
      "    accuracy                           0.70       134\n",
      "   macro avg       0.77      0.68      0.67       134\n",
      "weighted avg       0.76      0.70      0.68       134\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[26  0  3  6]\n",
      " [ 3  9  7 10]\n",
      " [ 5  0 25  5]\n",
      " [ 1  0  0 34]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        12Hz       0.92      0.85      0.88        13\n",
      "         6Hz       0.75      0.16      0.26        19\n",
      "        24Hz       0.50      0.77      0.61        13\n",
      "        30Hz       0.45      0.77      0.57        13\n",
      "\n",
      "    accuracy                           0.59        58\n",
      "   macro avg       0.66      0.64      0.58        58\n",
      "weighted avg       0.67      0.59      0.55        58\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[11  0  0  2]\n",
      " [ 0  3  7  9]\n",
      " [ 1  1 10  1]\n",
      " [ 0  0  3 10]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 10, weights = \"uniform\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev']\n",
    "}\n",
    "\n",
    "\n",
    "cv_splitter = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "tuned_clf_knn = GridSearchCV(estimator=knn, param_grid=param_grid,\n",
    "                    scoring='accuracy', refit='accuracy', cv=cv_splitter)\n",
    "\n",
    "tuned_clf_knn.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {tuned_clf_knn.best_params_}\")\n",
    "print(f\"Best cross-validation score: {tuned_clf_knn.best_score_:.3f}\")\n",
    "\n",
    "label_names = ['12Hz', '6Hz', '24Hz', '30Hz']\n",
    "\n",
    "with open(\"trained_model/KNN_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tuned_clf_knn, file)\n",
    "\n",
    "GetConfusionMatrix(tuned_clf_knn, x_train, x_test, y_train, y_test, label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
